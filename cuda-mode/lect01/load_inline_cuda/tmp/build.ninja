ninja_required_version = 1.3
cxx = c++

cflags = -DTORCH_EXTENSION_NAME=my_module -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /home/gpu/.conda/envs/py38/lib/python3.8/site-packages/torch/include -isystem /home/gpu/.conda/envs/py38/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /home/gpu/.conda/envs/py38/lib/python3.8/site-packages/torch/include/TH -isystem /home/gpu/.conda/envs/py38/lib/python3.8/site-packages/torch/include/THC -isystem /home/gpu/.conda/envs/py38/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17
post_cflags = 
cuda_dlink_post_cflags = 
ldflags = -shared -L/home/gpu/.conda/envs/py38/lib/python3.8/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python

rule compile
  command = $cxx -MMD -MF $out.d $cflags -c $in -o $out $post_cflags
  depfile = $out.d
  deps = gcc



rule link
  command = $cxx $in $ldflags -o $out

build main.o: compile /home/gpu/workspace/cuda-practice/cuda-mode/lect01/load_inline_cuda/tmp/main.cpp



build my_module.so: link main.o

default my_module.so
